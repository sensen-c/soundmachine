{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Audio Vectors\n",
    "Now that the labels have been extracted, we'll use the compiled csv (df_iemocap.csv) to split the original wav files into multiple frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:11:04.256048Z",
     "start_time": "2024-05-17T20:11:03.471876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try for one file first\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "# ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:11:08.172999Z",
     "start_time": "2024-05-17T20:11:06.326064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 0.4256729 ,  0.4850127 ,  0.3723262 , ..., -0.31710678,\n        -0.16457509,  0.        ], dtype=float32),\n 44100)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/sensenc/Downloads/IEMOCAP_full_release/Session1/dialog/wav/Ses01F_impro01.wav'\n",
    "\n",
    "y, sr = librosa.load(file_path, sr=44100)\n",
    "y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:11:09.869125Z",
     "start_time": "2024-05-17T20:11:09.674228Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('../data/preprocessing/df_iemocap.csv')\n",
    "iemocap_dir = '/Users/sensenc/Downloads/IEMOCAP_full_release/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells take some time until completely executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:20:06.471899Z",
     "start_time": "2024-05-17T20:11:11.797688Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:33<00:00,  3.35s/it]\n",
      " 97%|█████████▋| 30/31 [01:26<00:02,  2.43s/it]/Users/sensenc/anaconda3/envs/sound_detection_project/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "100%|██████████| 31/31 [01:26<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occured for Ses02F_script01_1.pk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:41<00:00,  3.16s/it]\n",
      "100%|██████████| 30/30 [01:40<00:00,  3.34s/it]\n",
      "100%|██████████| 31/31 [01:47<00:00,  3.46s/it]\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "for sess in range(1, 6):  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}Session{}/dialog/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "    with open('../data/preprocessing/audio_vectors_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
